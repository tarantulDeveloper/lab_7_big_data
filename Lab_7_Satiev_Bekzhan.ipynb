{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ddee96f-02df-4498-842a-286026136930",
   "metadata": {},
   "source": [
    "### Satiev Bekzhan\n",
    "### AIN-2-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336806aa-c1fe-42c1-9a6a-8be1753ab6f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T14:25:35.279680800Z",
     "start_time": "2023-12-14T14:24:58.130091800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "reviews_train = load_files('aclImdb_v3/aclImdb/train')\n",
    "text_train, y_train = reviews_train.data, reviews_train.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8069dbd3-1d80-4acb-b6b9-6ecc3ee269ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T14:25:35.455591100Z",
     "start_time": "2023-12-14T14:25:35.287236400Z"
    }
   },
   "outputs": [],
   "source": [
    "text_train = [doc.replace(b\"<br />\", b\" \") for doc in text_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0f30b9-5268-40ec-8fe1-e8385ff51664",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T14:25:46.982949900Z",
     "start_time": "2023-12-14T14:25:35.467440300Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews_test = load_files('aclImdb_v3/aclImdb/test')\n",
    "text_test, y_test = reviews_test.data, reviews_test.target\n",
    "text_test = [doc.replace(b\"<br />\", b\" \") for doc in text_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae2494e2-f607-40a3-a9cf-2a752ab30178",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T14:25:57.026097400Z",
     "start_time": "2023-12-14T14:25:46.989594100Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(max_features = 10000, max_df = .15)\n",
    "X = vect.fit_transform(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c688ef9-0e9f-4bcb-856d-5b4f78d53c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T14:29:31.444478Z",
     "start_time": "2023-12-14T14:25:57.026097400Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 6\u001B[0m\n\u001B[0;32m      2\u001B[0m lda \u001B[38;5;241m=\u001B[39m LatentDirichletAllocation(n_components \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m, learning_method \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m, max_iter \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m, random_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# Мы строим модель и преобразуем данные в один этап\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Преобразование займет некоторое время,\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# и мы можем сэкономить время, выполнив обе операции сразу\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m document_topics \u001B[38;5;241m=\u001B[39m lda\u001B[38;5;241m.\u001B[39mfit_transform(X)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    138\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 140\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m f(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    142\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[0;32m    143\u001B[0m         return_tuple \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    144\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[0;32m    145\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[0;32m    146\u001B[0m         )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:915\u001B[0m, in \u001B[0;36mTransformerMixin.fit_transform\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    911\u001B[0m \u001B[38;5;66;03m# non-optimized default implementation; override when a better\u001B[39;00m\n\u001B[0;32m    912\u001B[0m \u001B[38;5;66;03m# method is possible for a given clustering algorithm\u001B[39;00m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    914\u001B[0m     \u001B[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001B[39;00m\n\u001B[1;32m--> 915\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n\u001B[0;32m    916\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    917\u001B[0m     \u001B[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001B[39;00m\n\u001B[0;32m    918\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\u001B[38;5;241m.\u001B[39mtransform(X)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1144\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1146\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1147\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1148\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1149\u001B[0m     )\n\u001B[0;32m   1150\u001B[0m ):\n\u001B[1;32m-> 1151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_lda.py:673\u001B[0m, in \u001B[0;36mLatentDirichletAllocation.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    665\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_em_step(\n\u001B[0;32m    666\u001B[0m             X[idx_slice, :],\n\u001B[0;32m    667\u001B[0m             total_samples\u001B[38;5;241m=\u001B[39mn_samples,\n\u001B[0;32m    668\u001B[0m             batch_update\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    669\u001B[0m             parallel\u001B[38;5;241m=\u001B[39mparallel,\n\u001B[0;32m    670\u001B[0m         )\n\u001B[0;32m    671\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    672\u001B[0m     \u001B[38;5;66;03m# batch update\u001B[39;00m\n\u001B[1;32m--> 673\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_em_step(\n\u001B[0;32m    674\u001B[0m         X, total_samples\u001B[38;5;241m=\u001B[39mn_samples, batch_update\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, parallel\u001B[38;5;241m=\u001B[39mparallel\n\u001B[0;32m    675\u001B[0m     )\n\u001B[0;32m    677\u001B[0m \u001B[38;5;66;03m# check perplexity\u001B[39;00m\n\u001B[0;32m    678\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m evaluate_every \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m%\u001B[39m evaluate_every \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_lda.py:524\u001B[0m, in \u001B[0;36mLatentDirichletAllocation._em_step\u001B[1;34m(self, X, total_samples, batch_update, parallel)\u001B[0m\n\u001B[0;32m    497\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"EM update for 1 iteration.\u001B[39;00m\n\u001B[0;32m    498\u001B[0m \n\u001B[0;32m    499\u001B[0m \u001B[38;5;124;03mupdate `_component` by batch VB or online VB.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    520\u001B[0m \u001B[38;5;124;03m    Unnormalized document topic distribution.\u001B[39;00m\n\u001B[0;32m    521\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    523\u001B[0m \u001B[38;5;66;03m# E-step\u001B[39;00m\n\u001B[1;32m--> 524\u001B[0m _, suff_stats \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_e_step(\n\u001B[0;32m    525\u001B[0m     X, cal_sstats\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, random_init\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, parallel\u001B[38;5;241m=\u001B[39mparallel\n\u001B[0;32m    526\u001B[0m )\n\u001B[0;32m    528\u001B[0m \u001B[38;5;66;03m# M-step\u001B[39;00m\n\u001B[0;32m    529\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_update:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_lda.py:467\u001B[0m, in \u001B[0;36mLatentDirichletAllocation._e_step\u001B[1;34m(self, X, cal_sstats, random_init, parallel)\u001B[0m\n\u001B[0;32m    465\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m parallel \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    466\u001B[0m     parallel \u001B[38;5;241m=\u001B[39m Parallel(n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m--> 467\u001B[0m results \u001B[38;5;241m=\u001B[39m parallel(\n\u001B[0;32m    468\u001B[0m     delayed(_update_doc_distribution)(\n\u001B[0;32m    469\u001B[0m         X[idx_slice, :],\n\u001B[0;32m    470\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexp_dirichlet_component_,\n\u001B[0;32m    471\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdoc_topic_prior_,\n\u001B[0;32m    472\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_doc_update_iter,\n\u001B[0;32m    473\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmean_change_tol,\n\u001B[0;32m    474\u001B[0m         cal_sstats,\n\u001B[0;32m    475\u001B[0m         random_state,\n\u001B[0;32m    476\u001B[0m     )\n\u001B[0;32m    477\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m idx_slice \u001B[38;5;129;01min\u001B[39;00m gen_even_slices(X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], n_jobs)\n\u001B[0;32m    478\u001B[0m )\n\u001B[0;32m    480\u001B[0m \u001B[38;5;66;03m# merge result\u001B[39;00m\n\u001B[0;32m    481\u001B[0m doc_topics, sstats_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mresults)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     60\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[0;32m     61\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m     62\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[0;32m     64\u001B[0m )\n\u001B[1;32m---> 65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(iterable_with_config)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1085\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1077\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[0;32m   1078\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1082\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[0;32m   1083\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[0;32m   1084\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m-> 1085\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[0;32m   1086\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1088\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 901\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dispatch(tasks)\n\u001B[0;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[1;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend\u001B[38;5;241m.\u001B[39mapply_async(batch, callback\u001B[38;5;241m=\u001B[39mcb)\n\u001B[0;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[0;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[0;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[0;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[0;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[1;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m ImmediateResult(func)\n\u001B[0;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[0;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[0;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[0;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[1;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m batch()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[0;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[0;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[1;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    125\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[1;32m--> 127\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_lda.py:144\u001B[0m, in \u001B[0;36m_update_doc_distribution\u001B[1;34m(X, exp_topic_word_distr, doc_topic_prior, max_doc_update_iter, mean_change_tol, cal_sstats, random_state)\u001B[0m\n\u001B[0;32m    140\u001B[0m last_d \u001B[38;5;241m=\u001B[39m doc_topic_d\n\u001B[0;32m    142\u001B[0m \u001B[38;5;66;03m# The optimal phi_{dwk} is proportional to\u001B[39;00m\n\u001B[0;32m    143\u001B[0m \u001B[38;5;66;03m# exp(E[log(theta_{dk})]) * exp(E[log(beta_{dw})]).\u001B[39;00m\n\u001B[1;32m--> 144\u001B[0m norm_phi \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(exp_doc_topic_d, exp_topic_word_d) \u001B[38;5;241m+\u001B[39m eps\n\u001B[0;32m    146\u001B[0m doc_topic_d \u001B[38;5;241m=\u001B[39m exp_doc_topic_d \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mdot(cnts \u001B[38;5;241m/\u001B[39m norm_phi, exp_topic_word_d\u001B[38;5;241m.\u001B[39mT)\n\u001B[0;32m    147\u001B[0m \u001B[38;5;66;03m# Note: adds doc_topic_prior to doc_topic_d, in-place.\u001B[39;00m\n",
      "File \u001B[1;32m<__array_function__ internals>:200\u001B[0m, in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "lda = LatentDirichletAllocation(n_components = 10, learning_method = \"batch\", max_iter = 10, random_state = 0)\n",
    "# Мы строим модель и преобразуем данные в один этап\n",
    "# Преобразование займет некоторое время,\n",
    "# и мы можем сэкономить время, выполнив обе операции сразу\n",
    "document_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6d6c1-8f55-47be-b897-e31198f670cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T14:29:31.444478Z",
     "start_time": "2023-12-14T14:29:31.444478Z"
    }
   },
   "outputs": [],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6c035-056a-4597-8bb0-af308187242d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-14T14:29:31.444478Z",
     "start_time": "2023-12-14T14:29:31.444478Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sorting = np.argsort(lda.components_, axis = 1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393ee75-c638-4379-b247-2faa3663aef8",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.459988500Z"
    }
   },
   "outputs": [],
   "source": [
    "import mglearn\n",
    "\n",
    "mglearn.tools.print_topics(topics=range(10), feature_names = feature_names,\n",
    "sorting = sorting, topics_per_chunk = 5, n_words = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7123d5-5463-47c3-a2b8-8514789745cd",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.463997Z"
    }
   },
   "outputs": [],
   "source": [
    "lda100 = LatentDirichletAllocation(n_components = 100, learning_method = \"batch\", max_iter = 10, random_state = 0)\n",
    "document_topics100 = lda100.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06eefd3-dc6e-4add-9bb1-03d27a491803",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.463997Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "topics = np.array([7,16,24,25,28,36,37,45,51,53,54,63,89,97])\n",
    "\n",
    "sorting = np.argsort(lda100.components_, axis = 1)[:, ::-1]\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "mglearn.tools.pring_topics(topics = topics, feature_names = feature_names, sorting = sorting, topics_per_chunk = 7, n_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf8fc03-26cd-4a37-b12c-40a77059c66d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.463997Z"
    }
   },
   "outputs": [],
   "source": [
    "music = np.argsort(document_topics100[:, :45])(::-1)\n",
    "\n",
    "for i in music[:10]:\n",
    "    print(b\"\".join(text_train[i].split(b\".\")[:2]) + b\".\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c90f9-b9e7-4955-a3d7-890bd6855874",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.463997Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1,2, figsize = (10, 10))\n",
    "topic_names = [\"{:>2}\".format(i) + \" \".join(words)\n",
    "              for i, words in enumerate(feature_names[sorting[:,:2]])]\n",
    "\n",
    "for col in [0,1]:\n",
    "    start = col * 50\n",
    "    end = (col + 1) * 50\n",
    "    ax[col].barh(np.arange(50).np.sum(document_topics100, axis = 0)[start:end])\n",
    "    ax[col].set_yticks(np.arange(50))\n",
    "    ax[col].set_yticklabels(topic_names[start:end], ha = \"left\", va = \"top\")\n",
    "    ax[col].invert_yaxis()\n",
    "    ax[col].set_xlim(0,2000)\n",
    "    yax = ax[col].get_yaxis()\n",
    "    yax.set_tick_params(pad = 130)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5235d0a8-b24f-4175-986b-1d53cbdc4cf2",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.463997Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2cf2c260-8547-427d-90a3-0817156d1418",
   "metadata": {},
   "source": [
    "#### 1)Создание мешка слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92c138-5cf8-4dc0-b05d-1d6dd80c3068",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.474007200Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_reviews  = [\n",
    "    \"Отличное качество, всегда покупаю этот бренд.\",\n",
    "    \"Не понравился товар, бракованный.\",\n",
    "    \"Быстрая доставка, все пришло в целости и сохранности.\",\n",
    "    \"Удобный в использовании, рекомендую!\",\n",
    "    \"Цена слишком высокая, не соответствует качеству.\",\n",
    "    \"Надежный продукт, пользуюсь уже много лет.\",\n",
    "    \"Отвратительный опыт, товар пришел поврежденный.\",\n",
    "    \"Прекрасный выбор, доволен покупкой.\",\n",
    "    \"Не оправдал ожидания, не советую.\",\n",
    "    \"Отличный сервис, оперативная поддержка.\",\n",
    "    \"Эффективный продукт, рекомендую для использования.\",\n",
    "    \"Продукция этой компании всегда высокого качества.\",\n",
    "    \"Недовольство качеством, не стоит своих денег.\",\n",
    "    \"Хорошее соотношение цены и качества.\",\n",
    "    \"Надежный бренд, доволен покупкой.\",\n",
    "    \"Неудачный опыт, не буду больше покупать у этого производителя.\",\n",
    "    \"Инновационный продукт, радует новыми возможностями.\",\n",
    "    \"Необычный дизайн, отличается от других аналогов.\",\n",
    "    \"Низкое качество, не рекомендую к покупке.\",\n",
    "    \"Отличный выбор для повседневного использования.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16950b9e-107c-4c0f-abb5-87d9f8e6ac13",
   "metadata": {},
   "source": [
    "#### 2) Создание словаря стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a76d05-d529-404b-9b0a-b7633254e6f7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.474007200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "custom_stop_words = set([\"всегда\", \"не\", \"и\", \"в\", \"все\", \"целости\", \"и\", \"в\", \"с\", \"не\", \n",
    "    \"для\", \"поддержка\", \"этой\", \"это\", \"не\", \"не\", \"и\", \"больше\", \"у\", \n",
    "    \"не\", \"для\", \"по\", \"не\", \"от\", \"не\", \"не\", \"для\", \"не\", \"не\", \"и\", \n",
    "    \"для\", \"для\", \"по\", \"не\", \"не\", \"не\", \"не\", \"и\", \"не\", \"не\", \"для\", \n",
    "    \"не\", \"не\", \"не\", \"не\", \"для\", \"повседневного\", \"использования\"])\n",
    "\n",
    "text_custom = [\" \".join(doc.split()) for doc in custom_reviews]\n",
    "text_custom_no_stop = [\" \".join([word for word in doc.split() if word.lower() not in custom_stop_words]) for doc in text_custom]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de85bd8b-d19a-49a4-ad6a-f0d202659af9",
   "metadata": {},
   "source": [
    "#### 3) Масштабирование данных с помощью tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659be8f0-2223-444d-9b94-512499dbd76a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.474007200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(text_custom_no_stop)\n",
    "y_custom = np.array([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036fafb-eab9-4bdf-bb55-9f5cc7085da2",
   "metadata": {},
   "source": [
    "#### 4) Исследование коэффициентов модели и Выводы по работе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c2a4e-aede-4c4a-8ad6-e91a02681580",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.474007200Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_tfidf, y_custom)  \n",
    "\n",
    "coefficients = model.coef_[0]\n",
    "feature_names_tfidf = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "for i, word in enumerate(feature_names_tfidf):\n",
    "    print(f\"{word}: {coefficients[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37ebb50-7b61-4f1b-a4a8-d49d1786fe41",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-12-14T14:29:31.474007200Z"
    }
   },
   "outputs": [],
   "source": [
    "##Знак коэффициента указывает на направление влияния: \n",
    "##положительный для положительного влияния, отрицательный - для отрицательного."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
